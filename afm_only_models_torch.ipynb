{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df973d61",
   "metadata": {},
   "source": [
    "## Define Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7a6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder containing .spm files\n",
    "folder_path = r\"C:\\Users\\cobia\\OneDrive - University of Cambridge\\Python\\afm_data\\all_images_03_08_2025\"\n",
    "\n",
    "spm_files = [f for f in os.listdir(folder_path) if f.endswith('.spm')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4eb5a1",
   "metadata": {},
   "source": [
    "## Modules and Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e137c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "def generate_circular_mask(center_x, center_y, radius, shape=(512, 512)):\n",
    "    Y, X = np.ogrid[:shape[0], :shape[1]]\n",
    "    dist_from_center = np.sqrt((X - center_x) ** 2 + (Y - center_y) ** 2)\n",
    "    return dist_from_center <= radius\n",
    "\n",
    "def load_afm_dataset(folder_path, spm_files):\n",
    "    dataset = []\n",
    "    category_to_id = {\"small\": 0, \"large\": 1}\n",
    "\n",
    "    for idx, filename in enumerate(spm_files):\n",
    "        afm_file = os.path.join(folder_path, f\"{filename}_corrected.csv\")\n",
    "        label_file = os.path.join(folder_path, f\"{filename}_categorised.csv\")\n",
    "\n",
    "        afm_data = pd.read_csv(afm_file).values\n",
    "        label_data = pd.read_csv(label_file)\n",
    "\n",
    "        # Create image\n",
    "        image = (afm_data - np.min(afm_data)) / (np.max(afm_data) - np.min(afm_data)) * 255\n",
    "        image = image.astype(np.uint8)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        img_path = os.path.join(folder_path, f\"{filename}.png\")\n",
    "        cv2.imwrite(img_path, image)\n",
    "\n",
    "        record = {\n",
    "            \"file_name\": img_path,\n",
    "            \"image_id\": idx,\n",
    "            \"height\": 512,\n",
    "            \"width\": 512,\n",
    "            \"annotations\": []\n",
    "        }\n",
    "\n",
    "        for _, row in label_data.iterrows():\n",
    "            if row['category'] == 'combination':\n",
    "                continue\n",
    "\n",
    "            x, y, area, cat = row['x'], row['y'], row['size'], row['category']\n",
    "            radius = np.sqrt(area / np.pi)\n",
    "\n",
    "            mask = generate_circular_mask(x, y, radius)\n",
    "            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            if len(contours) == 0:\n",
    "                continue\n",
    "\n",
    "            segmentation = contours[0].flatten().tolist()\n",
    "            bbox = cv2.boundingRect(contours[0])\n",
    "\n",
    "            record[\"annotations\"].append({\n",
    "                \"bbox\": list(bbox),\n",
    "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                \"segmentation\": [segmentation],\n",
    "                \"category_id\": category_to_id[cat],\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "\n",
    "        dataset.append(record)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c6034",
   "metadata": {},
   "source": [
    "## Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3afd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "def register_afm_dataset(folder_path, spm_files):\n",
    "    DatasetCatalog.register(\"afm_spots\", lambda: load_afm_dataset(folder_path, spm_files))\n",
    "    MetadataCatalog.get(\"afm_spots\").set(thing_classes=[\"small\", \"large\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e58f0e",
   "metadata": {},
   "source": [
    "## Train with Detectron2 (Mask R-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad568ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "def train_model(output_dir=\"./output\"):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "    cfg.DATASETS.TRAIN = (\"afm_spots\",)\n",
    "    cfg.DATASETS.TEST = ()\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    cfg.SOLVER.BASE_LR = 0.00025\n",
    "    cfg.SOLVER.MAX_ITER = 1000\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "    cfg.OUTPUT_DIR = output_dir\n",
    "\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "    return cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa52ff",
   "metadata": {},
   "source": [
    "## Visualize and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba5566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from sklearn.metrics import classification_report\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "def evaluate_model(cfg, dataset_dicts):\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    metadata = MetadataCatalog.get(\"afm_spots\")\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for d in dataset_dicts:\n",
    "        im = cv2.imread(d[\"file_name\"])\n",
    "        outputs = predictor(im)\n",
    "        pred_classes = outputs[\"instances\"].pred_classes.cpu().numpy()\n",
    "\n",
    "        gt_classes = [ann[\"category_id\"] for ann in d[\"annotations\"]]\n",
    "        y_true.extend(gt_classes)\n",
    "        y_pred.extend(pred_classes[:len(gt_classes)])\n",
    "\n",
    "        v = Visualizer(im[:, :, ::-1],\n",
    "                       metadata=metadata,\n",
    "                       scale=1.0,\n",
    "                       instance_mode=ColorMode.IMAGE_BW)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(out.get_image())\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"small\", \"large\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7932915c",
   "metadata": {},
   "source": [
    "## Full Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93fefaff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m register_afm_dataset(folder_path, spm_files)\n\u001b[1;32m----> 2\u001b[0m train_cfg \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m evaluate_model(train_cfg, load_afm_dataset(folder_path, spm_files))\n",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(output_dir)\u001b[0m\n\u001b[0;32m     19\u001b[0m cfg\u001b[38;5;241m.\u001b[39mOUTPUT_DIR \u001b[38;5;241m=\u001b[39m output_dir\n\u001b[0;32m     21\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(cfg\u001b[38;5;241m.\u001b[39mOUTPUT_DIR, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mDefaultTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m trainer\u001b[38;5;241m.\u001b[39mresume_or_load(resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\cobia\\anaconda3\\envs\\lumispytorch\\lib\\site-packages\\detectron2\\engine\\defaults.py:410\u001b[0m, in \u001b[0;36mDefaultTrainer.__init__\u001b[1;34m(self, cfg)\u001b[0m\n\u001b[0;32m    407\u001b[0m cfg \u001b[38;5;241m=\u001b[39m DefaultTrainer\u001b[38;5;241m.\u001b[39mauto_scale_workers(cfg, comm\u001b[38;5;241m.\u001b[39mget_world_size())\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# Assume these objects must be constructed in this order.\u001b[39;00m\n\u001b[1;32m--> 410\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_optimizer(cfg, model)\n\u001b[0;32m    412\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_train_loader(cfg)\n",
      "File \u001b[1;32mc:\\Users\\cobia\\anaconda3\\envs\\lumispytorch\\lib\\site-packages\\detectron2\\engine\\defaults.py:550\u001b[0m, in \u001b[0;36mDefaultTrainer.build_model\u001b[1;34m(cls, cfg)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(\u001b[38;5;28mcls\u001b[39m, cfg):\n\u001b[0;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m        torch.nn.Module:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Overwrite it if you'd like a different model.\u001b[39;00m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 550\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m     logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    552\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model))\n",
      "File \u001b[1;32mc:\\Users\\cobia\\anaconda3\\envs\\lumispytorch\\lib\\site-packages\\detectron2\\modeling\\meta_arch\\build.py:23\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(cfg)\u001b[0m\n\u001b[0;32m     21\u001b[0m meta_arch \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mMETA_ARCHITECTURE\n\u001b[0;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m META_ARCH_REGISTRY\u001b[38;5;241m.\u001b[39mget(meta_arch)(cfg)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m _log_api_usage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodeling.meta_arch.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m meta_arch)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\cobia\\anaconda3\\envs\\lumispytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cobia\\anaconda3\\envs\\lumispytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cobia\\anaconda3\\envs\\lumispytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cobia\\anaconda3\\envs\\lumispytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cobia\\anaconda3\\envs\\lumispytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\cobia\\anaconda3\\envs\\lumispytorch\\lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "register_afm_dataset(folder_path, spm_files)\n",
    "train_cfg = train_model()\n",
    "evaluate_model(train_cfg, load_afm_dataset(folder_path, spm_files))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumispytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
