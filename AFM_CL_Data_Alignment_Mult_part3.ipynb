{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791fbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc1b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histograms of spot depths and spot sizes across all images\n",
    "spot_depths_all_flattened = [depth for sublist in spot_depths_all for depth in sublist]\n",
    "spot_sizes_all_flattened = [size * 34.332 for sublist in spot_sizes_all for size in sublist]  # convert to nm^2\n",
    "\n",
    "plt.figure(figsize=(10, 14))\n",
    "\n",
    "# Top subplot: Histogram of spot depths\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(spot_depths_all_flattened, bins=28, color='green', alpha=0.7)\n",
    "plt.title('Histogram of Spot Depths Across All Images')\n",
    "plt.xlabel('Spot Depth (mean intensity)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Bottom subplot: Histogram of spot sizes\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(spot_sizes_all_flattened, bins=28, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of Spot Sizes Across 10 3 $\\mu m \\\\times$ 3 $\\mu m$ AFM Images of Silane-Treated Sample')\n",
    "plt.xlabel('Spot Size ($nm^2$)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97154bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_dict['si_old_zoomed_02.0_00000_grey.png'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279407bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\Users\\cobia\\OneDrive - University of Cambridge\\Python\\afm_data\\all_images_03_08_2025\"\n",
    "label_files = [os.path.join(folder_path, f\"{os.path.splitext(filename)[0]}_categorised.csv\") for filename in all_data_dict.keys()]\n",
    "\n",
    "for label_file in label_files:\n",
    "    print(os.path.exists(label_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1b153a",
   "metadata": {},
   "source": [
    "## Old Patch Generator (with median spot size calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc14300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Prepare the dataset\n",
    "patches = []\n",
    "labels = []\n",
    "\n",
    "def load_feature_points(csv_path):\n",
    "    \"\"\"Load feature points from CSV file.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    source_points = df[['x2', 'y2']].values  # Feature positions in image 1\n",
    "    target_points = df[['x1', 'y1']].values  # Corresponding positions in image 2\n",
    "    return source_points, target_points\n",
    "\n",
    "for file, data in all_data_dict.items():\n",
    "    if True: #file == 'fat_end_outside_L_03.0_00000.png':\n",
    "        print('file: ', file)\n",
    "        spots = data['spots']\n",
    "        print('spots: ', len(spots))\n",
    "        spot_sizes = data['spot_sizes']\n",
    "        afm_img = data['afm_img']\n",
    "        rbf_x = data['rbf_x']\n",
    "        rbf_y = data['rbf_y']\n",
    "        cl_img = data['cl_img']\n",
    "        cl_raw = data['cl_raw']\n",
    "        cl_centre = data['m_centre'].data\n",
    "        cl_intensity = data['m_intensity'].data\n",
    "        cl_fwhm = data['m_fwhm'].data\n",
    "\n",
    "        source_points, target_points = load_feature_points(data['alignment_file'])\n",
    "\n",
    "        h, w = afm_img.shape[:2]\n",
    "\n",
    "        # Create a grid of pixel coordinates\n",
    "        grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "        grid_points = np.column_stack([grid_x.ravel(), grid_y.ravel()])\n",
    "\n",
    "        # Interpolate transformation using RBF (thin-plate spline kernel)\n",
    "        rbf_x = RBFInterpolator(source_points, target_points[:, 0], kernel='thin_plate_spline')\n",
    "        rbf_y = RBFInterpolator(source_points, target_points[:, 1], kernel='thin_plate_spline')\n",
    "\n",
    "        # Compute the transformed coordinates\n",
    "        warped_x = rbf_x(grid_points).reshape(h, w).astype(np.float32)\n",
    "        warped_y = rbf_y(grid_points).reshape(h, w).astype(np.float32)\n",
    "        \n",
    "        warped_image_afm = cv2.remap(afm_img, warped_x, warped_y, interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Classify spots into largest 50% and smallest 50%\n",
    "        median_size = np.percentile(spot_sizes, 41) #np.median(spot_sizes)\n",
    "\n",
    "        cl_spot_coords = []\n",
    "\n",
    "        for spot, size in zip(spots, spot_sizes):\n",
    "            # Get the AFM spot coordinates\n",
    "            afm_coords = np.array(spot.centroid)\n",
    "            \n",
    "            # Map to CL image coordinates\n",
    "            blank_array = np.zeros_like(afm_img)\n",
    "            blank_array[int(afm_coords[0]), int(afm_coords[1])] = 255\n",
    "            blank_array[int(afm_coords[0]), int(afm_coords[1]+1)] = 127\n",
    "            blank_array[int(afm_coords[0]), int(afm_coords[1]-1)] = 127\n",
    "            blank_array[int(afm_coords[0]+1), int(afm_coords[1])] = 127\n",
    "            blank_array[int(afm_coords[0]-1), int(afm_coords[1])] = 127\n",
    "            blank_array[int(afm_coords[0]+1), int(afm_coords[1]+1)] = 127\n",
    "            blank_array[int(afm_coords[0]+1), int(afm_coords[1]-1)] = 127\n",
    "            blank_array[int(afm_coords[0]-1), int(afm_coords[1]+1)] = 127\n",
    "            blank_array[int(afm_coords[0]-1), int(afm_coords[1]-1)] = 127\n",
    "            # Use RBF to get CL coordinates\n",
    "            warped_image = cv2.remap(blank_array, warped_x, warped_y, interpolation=cv2.INTER_CUBIC)\n",
    "            # Find the maximum value in warped_image\n",
    "            max_value = np.max(warped_image)\n",
    "            # Find the coordinates of the maximum value\n",
    "            max_coords = np.argwhere(warped_image == max_value)\n",
    "\n",
    "            cl_x, cl_y = max_coords[0]  # Get the first coordinate pair\n",
    "            print(f'AFM coordinates are {afm_coords[0]} and {afm_coords[1]}')\n",
    "            print(f'CL coordinates are {cl_x} and {cl_y}')\n",
    "\n",
    "            cl_spot_coords.append((cl_x, cl_y))\n",
    "\n",
    "            # Extract a 15x15 patch around the spot\n",
    "            half_size = 7  # Half of 15px\n",
    "\n",
    "            print('cl_img size = ', cl_img.shape)\n",
    "\n",
    "            if (cl_y - half_size >= 0 and cl_y + half_size < cl_img.shape[0] and\n",
    "                cl_x - half_size >= 0 and cl_x + half_size < cl_img.shape[1]):\n",
    "                patch_centre = cl_centre[cl_y - half_size:cl_y + half_size + 1, cl_x - half_size:cl_x + half_size + 1]\n",
    "                patch_intensity = cl_intensity[cl_y - half_size:cl_y + half_size + 1, cl_x - half_size:cl_x + half_size + 1]\n",
    "                patch_fwhm = cl_fwhm[cl_y - half_size:cl_y + half_size + 1, cl_x - half_size:cl_x + half_size + 1]\n",
    "                patch_raw = cl_raw[cl_y - half_size:cl_y + half_size + 1, cl_x - half_size:cl_x + half_size + 1, :]\n",
    "                patch = np.stack((patch_centre,\n",
    "                                  patch_intensity,\n",
    "                                  patch_fwhm), axis=-1)\n",
    "                # patch = patch_raw\n",
    "                patches.append(patch)\n",
    "                labels.append(1 if size > median_size else 0)\n",
    "        \n",
    "print('total number of patches = ', len(patches))\n",
    "print('total number of labels = ', len(labels))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "patches = np.array(patches)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(patches.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f3918",
   "metadata": {},
   "source": [
    "## New Spot Generator (from label files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "\n",
    "def load_feature_points(csv_path):\n",
    "    \"\"\"Load feature points from CSV file.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    source_points = df[['x1', 'y1']].values  # Feature positions in image 1\n",
    "    target_points = df[['x2', 'y2']].values  # Corresponding positions in image 2\n",
    "    return source_points, target_points\n",
    "\n",
    "\n",
    "folder_path = r\"C:\\Users\\cobia\\OneDrive - University of Cambridge\\Python\\afm_data\\all_images_03_08_2025\"\n",
    "\n",
    "patches = []\n",
    "labels = []\n",
    "\n",
    "for file, data in all_data_dict.items():\n",
    "    print('file:', file)\n",
    "\n",
    "    # Load the label file\n",
    "    label_file = os.path.join(\n",
    "        folder_path, f\"{os.path.splitext(file)[0]}_categorised.csv\"\n",
    "    )\n",
    "    label_df = pd.read_csv(label_file)\n",
    "\n",
    "    afm_img = data['afm_img']\n",
    "    cl_img = data['cl_img']\n",
    "    cl_centre = data['m_centre'].data\n",
    "    cl_intensity = data['m_intensity'].data\n",
    "    cl_fwhm = data['m_fwhm'].data\n",
    "    cl_raw = data['cl_raw']\n",
    "\n",
    "    source_points, target_points = load_feature_points(data['alignment_file'])\n",
    "    h, w = afm_img.shape[:2]\n",
    "\n",
    "    # Prepare coordinate transform\n",
    "    grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    grid_points = np.column_stack([grid_x.ravel(), grid_y.ravel()])\n",
    "    # rbf_x = RBFInterpolator(source_points, target_points[:, 0], kernel='thin_plate_spline')\n",
    "    # rbf_y = RBFInterpolator(source_points, target_points[:, 1], kernel='thin_plate_spline')\n",
    "    rbf_x = RBFInterpolator(target_points, source_points[:, 0], kernel='thin_plate_spline')\n",
    "    rbf_y = RBFInterpolator(target_points, source_points[:, 1], kernel='thin_plate_spline')\n",
    "\n",
    "    warped_x = rbf_x(grid_points).reshape(h, w).astype(np.float32)\n",
    "    warped_y = rbf_y(grid_points).reshape(h, w).astype(np.float32)\n",
    "\n",
    "    # Loop through labeled spots\n",
    "    for _, row in label_df.iterrows():\n",
    "        if row['category'] not in ['large', 'small']:\n",
    "            continue  # skip unlabeled or irrelevant\n",
    "\n",
    "        afm_x, afm_y = row['x'], 511-row['y']  # adjust y as per original plotting code\n",
    "\n",
    "        # Create a small mask at AFM coords\n",
    "        blank_array = np.zeros_like(afm_img)\n",
    "        offsets = [(0, 0), (0, 1), (0, -1), (1, 0), (-1, 0),\n",
    "                   (1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "        for dy, dx in offsets:\n",
    "            yy = int(afm_y + dy)\n",
    "            xx = int(afm_x + dx)\n",
    "            if 0 <= yy < blank_array.shape[0] and 0 <= xx < blank_array.shape[1]:\n",
    "                blank_array[yy, xx] = 255 if (dy, dx) == (0, 0) else 127\n",
    "\n",
    "        # Warp to CL coords\n",
    "        warped_image = cv2.remap(blank_array, warped_x, warped_y, interpolation=cv2.INTER_CUBIC)\n",
    "        max_coords = np.argwhere(warped_image == np.max(warped_image))\n",
    "        cl_x, cl_y = max_coords[0]  # first max coordinate\n",
    "\n",
    "        # Extract patch around CL spot\n",
    "        half_size = 7\n",
    "        if (cl_y - half_size >= 0 and cl_y + half_size < cl_img.shape[0] and\n",
    "            cl_x - half_size >= 0 and cl_x + half_size < cl_img.shape[1]):\n",
    "            patch_centre = cl_centre[cl_y - half_size:cl_y + half_size + 1,\n",
    "                                     cl_x - half_size:cl_x + half_size + 1]\n",
    "            patch_intensity = cl_intensity[cl_y - half_size:cl_y + half_size + 1,\n",
    "                                           cl_x - half_size:cl_x + half_size + 1]\n",
    "            patch_fwhm = cl_fwhm[cl_y - half_size:cl_y + half_size + 1,\n",
    "                                 cl_x - half_size:cl_x + half_size + 1]\n",
    "            patch = np.stack((patch_centre, patch_intensity, patch_fwhm), axis=-1)\n",
    "\n",
    "            patches.append(patch)\n",
    "            labels.append(1 if row['category'] == 'large' else 0)\n",
    "\n",
    "print('Total number of patches:', len(patches))\n",
    "print('Total number of labels:', len(labels))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "patches = np.array(patches)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('Patches shape:', patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae007b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def show_afm_cl_with_labels(afm_img, cl_img, label_file, rbf_x, rbf_y):\n",
    "    \"\"\"\n",
    "    afm_img: 2D numpy array (AFM data)\n",
    "    cl_img:  2D numpy array (CL data)\n",
    "    label_file: path to the *_categorised.csv file\n",
    "    rbf_x, rbf_y: fitted RBFInterpolators mapping AFM -> CL coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    # Load labels\n",
    "    labels_df = pd.read_csv(label_file)\n",
    "\n",
    "    # Extract relevant rows (large/small spots only)\n",
    "    labels_df = labels_df[labels_df['category'].isin(['large', 'small'])].reset_index(drop=True)\n",
    "\n",
    "    # Prepare figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # ---- AFM image ----\n",
    "    axes[0].imshow(afm_img, cmap='afmhot')\n",
    "    axes[0].set_title(\"AFM image (original coords)\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for idx, row in labels_df.iterrows():\n",
    "        afm_x, afm_y = row['x'], 511-row['y']\n",
    "        # AFM image is usually (row = y, col = x), but labels may be in x,y\n",
    "        axes[0].scatter(afm_x, afm_img.shape[0] - afm_y, c='cyan', s=20)\n",
    "        axes[0].text(afm_x + 2, afm_img.shape[0] - afm_y, str(idx), color='white', fontsize=8)\n",
    "\n",
    "    # ---- CL image ----\n",
    "    axes[1].imshow(cl_img, cmap='viridis')\n",
    "    axes[1].set_title(\"CL image (mapped coords)\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    for idx, row in labels_df.iterrows():\n",
    "        afm_x, afm_y = row['x'], row['y']\n",
    "\n",
    "        # Map coordinates: RBF expects col, row (x, y)\n",
    "        mapped_x = rbf_x([[afm_x, afm_y]])[0]\n",
    "        mapped_y = rbf_y([[afm_x, afm_y]])[0]\n",
    "\n",
    "        # Scatter in CL image coords\n",
    "        axes[1].scatter(mapped_x, mapped_y, c='cyan', s=20)\n",
    "        axes[1].text(mapped_x + 2, mapped_y, str(idx), color='white', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "for afm_img, cl_img, label_file, rbf_x, rbf_y in zip(afm_img_list, cl_img_list, label_file_list, rbf_x_list, rbf_y_list):\n",
    "    show_afm_cl_with_labels(afm_img, cl_img, label_file, rbf_x, rbf_y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c10ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def interactive_cl_view(afm_img, cl_img, label_file, rbf_x, rbf_y, cl_intensity):\n",
    "    \"\"\"\n",
    "    Interactive viewer for CL image patches.\n",
    "    Click a CL spot to display its patch and draw bounding box.\n",
    "\n",
    "    afm_img: 2D numpy array (AFM data)\n",
    "    cl_img:  2D numpy array (CL data)\n",
    "    label_file: path to *_categorised.csv file\n",
    "    rbf_x, rbf_y: RBFInterpolators (CL→AFM fit, used AFM→CL mapping)\n",
    "    cl_intensity: 2D numpy array of CL intensity channel\n",
    "    \"\"\"\n",
    "    label_df = pd.read_csv(label_file)\n",
    "    label_df = label_df[label_df['category'].isin(['large', 'small'])].reset_index(drop=True)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(afm_img, cmap='afmhot')\n",
    "    axes[0].set_title(\"AFM Image\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Plot AFM points\n",
    "    for idx, row in label_df.iterrows():\n",
    "        afm_x, afm_y = row['x'], row['y']\n",
    "        axes[0].scatter(afm_x, afm_y, c='cyan', s=20)\n",
    "        axes[0].text(afm_x + 2, afm_y, str(idx), color='white', fontsize=8)\n",
    "\n",
    "    axes[1].imshow(cl_img, cmap='viridis')\n",
    "    axes[1].set_title(\"CL Image (click to view patch)\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    cl_points = []\n",
    "    for idx, row in label_df.iterrows():\n",
    "        afm_x, afm_y = row['x'], row['y']\n",
    "        mapped_x = rbf_x([[afm_x, afm_y]])[0]\n",
    "        mapped_y = rbf_y([[afm_x, afm_y]])[0]\n",
    "        cl_points.append((mapped_x, mapped_y))\n",
    "        axes[1].scatter(mapped_x, mapped_y, c='cyan', s=20)\n",
    "        axes[1].text(mapped_x + 2, mapped_y, str(idx), color='white', fontsize=8)\n",
    "\n",
    "    rect_artist = None\n",
    "\n",
    "    def onclick(event):\n",
    "        nonlocal rect_artist\n",
    "        if event.inaxes != axes[1]:\n",
    "            return\n",
    "\n",
    "        # Find nearest spot\n",
    "        click_x, click_y = event.xdata, event.ydata\n",
    "        dists = [np.hypot(px - click_x, py - click_y) for px, py in cl_points]\n",
    "        nearest_idx = int(np.argmin(dists))\n",
    "        spot_x, spot_y = cl_points[nearest_idx]\n",
    "\n",
    "        # Round to integer coords\n",
    "        spot_x = int(round(spot_x))\n",
    "        spot_y = int(round(spot_y))\n",
    "\n",
    "        # Draw bounding box on CL image\n",
    "        half_size = 7\n",
    "        if rect_artist:\n",
    "            rect_artist.remove()\n",
    "        rect_artist = patches.Rectangle(\n",
    "            (spot_x - half_size, spot_y - half_size),\n",
    "            15, 15, linewidth=1.5, edgecolor='red', facecolor='none'\n",
    "        )\n",
    "        axes[1].add_patch(rect_artist)\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "        # Extract patch\n",
    "        if (spot_y - half_size >= 0 and spot_y + half_size < cl_intensity.shape[0] and\n",
    "            spot_x - half_size >= 0 and spot_x + half_size < cl_intensity.shape[1]):\n",
    "            patch = cl_intensity[spot_y - half_size:spot_y + half_size + 1,\n",
    "                                 spot_x - half_size:spot_x + half_size + 1]\n",
    "\n",
    "            # Show patch in new figure\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            plt.imshow(patch, cmap='inferno')\n",
    "            plt.title(f\"Patch for spot {nearest_idx}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "interactive_cl_view(\n",
    "    afm_img,\n",
    "    cl_img,\n",
    "    label_file,\n",
    "    rbf_x,\n",
    "    rbf_y,\n",
    "    cl_intensity=data['m_intensity'].data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9496cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "\n",
    "patches = []\n",
    "labels = []\n",
    "\n",
    "afm_img_list, cl_img_list, label_file_list, rbf_x_list, rbf_y_list = [],[],[],[],[]\n",
    "\n",
    "def load_feature_points(csv_path):\n",
    "    \"\"\"Load feature points from CSV file.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    source_points = df[['x2', 'y2']].values  # Feature positions in image 1\n",
    "    target_points = df[['x1', 'y1']].values  # Corresponding positions in image 2\n",
    "    return source_points, target_points\n",
    "\n",
    "for file, data in all_data_dict.items():\n",
    "    print('Processing file:', file)\n",
    "\n",
    "    # Load label file\n",
    "    label_file = os.path.join(\n",
    "        folder_path, f\"{os.path.splitext(file)[0]}_categorised.csv\"\n",
    "    )\n",
    "    label_file_list.append(label_file)\n",
    "    label_df = pd.read_csv(label_file)\n",
    "    label_df = label_df[label_df['category'].isin(['large', 'small'])].reset_index(drop=True)\n",
    "\n",
    "    # Extract images\n",
    "    afm_img = data['afm_img']\n",
    "    afm_img_list.append(afm_img)\n",
    "    cl_img = data['cl_img']\n",
    "    cl_centre = data['m_centre'].data\n",
    "    cl_intensity = data['m_intensity'].data\n",
    "    cl_img_list.append(cl_intensity)\n",
    "    cl_fwhm = data['m_fwhm'].data\n",
    "    cl_raw = data['cl_raw']\n",
    "\n",
    "    # Load feature points (alignment)\n",
    "    source_points, target_points = load_feature_points(data['alignment_file'])\n",
    "\n",
    "    # Fit RBF in CL → AFM direction (to match your working setup)\n",
    "    rbf_x = RBFInterpolator(target_points, source_points[:, 0], kernel='thin_plate_spline')\n",
    "    rbf_y = RBFInterpolator(target_points, source_points[:, 1], kernel='thin_plate_spline')\n",
    "\n",
    "    rbf_x_list.append(rbf_x)\n",
    "    rbf_y_list.append(rbf_y)\n",
    "\n",
    "    # Process each labelled spot\n",
    "    for _, row in label_df.iterrows():\n",
    "        afm_x, afm_y = row['x'], 511 - row['y']  # Y-flip for AFM coordinates\n",
    "\n",
    "        # Map AFM coords to CL coords\n",
    "        mapped_x = rbf_x([[afm_x, afm_y]])[0]\n",
    "        mapped_y = rbf_y([[afm_x, afm_y]])[0]\n",
    "\n",
    "        # Round to nearest int for indexing\n",
    "        cl_x, cl_y = int(round(mapped_x)), int(round(mapped_y))\n",
    "\n",
    "        half_size = 7  # Half of 15 px patch\n",
    "\n",
    "        # Ensure patch is within bounds\n",
    "        if (cl_y - half_size >= 0 and cl_y + half_size < cl_img.shape[0] and\n",
    "            cl_x - half_size >= 0 and cl_x + half_size < cl_img.shape[1]):\n",
    "\n",
    "            patch_centre = cl_centre[cl_y - half_size:cl_y + half_size + 1,\n",
    "                                     cl_x - half_size:cl_x + half_size + 1]\n",
    "            patch_intensity = cl_intensity[cl_y - half_size:cl_y + half_size + 1,\n",
    "                                           cl_x - half_size:cl_x + half_size + 1]\n",
    "            patch_fwhm = cl_fwhm[cl_y - half_size:cl_y + half_size + 1,\n",
    "                                 cl_x - half_size:cl_x + half_size + 1]\n",
    "\n",
    "            patch = np.stack((patch_centre, patch_intensity, patch_fwhm), axis=-1)\n",
    "            patches.append(patch)\n",
    "\n",
    "            # Label: large = 1, small = 0\n",
    "            labels.append(1 if row['category'] == 'large' else 0)\n",
    "\n",
    "print('Total patches:', len(patches))\n",
    "print('Total labels:', len(labels))\n",
    "\n",
    "patches = np.array(patches)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('Patch array shape:', patches.shape)\n",
    "print('Label array shape:', labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bd1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ad83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Pick 10 random indices\n",
    "num_to_show = min(20, len(patches))\n",
    "indices = random.sample(range(len(patches)), num_to_show)\n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(9, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, idx in zip(axes, indices):\n",
    "    patch = patches[idx,:,:,1]\n",
    "    label = 'Large' if labels[idx] == 1 else 'Small'\n",
    "    \n",
    "    # Display as RGB-like by normalizing per channel\n",
    "    patch_display = patch.copy().astype(float)\n",
    "    # for c in range(patch_display.shape[-1]):\n",
    "    #     ch_min, ch_max = patch_display[..., c].min(), patch_display[..., c].max()\n",
    "    #     if ch_max > ch_min:\n",
    "    #         patch_display[..., c] = (patch_display[..., c] - ch_min) / (ch_max - ch_min)\n",
    "    \n",
    "    ax.imshow(patch_display, cmap='viridis')\n",
    "    ax.set_title(f\"{label} Spot\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(11, 5))\n",
    "\n",
    "# Plot AFM image with numbered spots\n",
    "axes[0].imshow(afm_img, cmap='gray')\n",
    "axes[0].set_title(\"AFM Image with Numbered Spots\")\n",
    "for i, spot in enumerate(spots):\n",
    "    cy, cx = spot.centroid\n",
    "    # axes[0].scatter(cx, cy, color='red', s=20)\n",
    "    axes[0].text(cx, cy, str(i + 1), color='yellow', fontsize=8, ha='center', va='center')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(blank_array, cmap='grey')\n",
    "axes[1].set_title(\"Generated Image with 1 White Spot (Spot 48)\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Plot CL image with numbered spots\n",
    "axes[2].imshow(cl_img, cmap='viridis')\n",
    "axes[2].imshow(warped_image_afm, alpha=0.3, cmap='afmhot')\n",
    "axes[2].set_title(\"CL Image with Numbered Spots\")\n",
    "for i, (cl_x, cl_y) in enumerate(cl_spot_coords):\n",
    "    # axes[1].scatter(cl_y, cl_x, color='blue', s=20)\n",
    "    axes[2].text(cl_y, cl_x, str(i + 1), color='white', fontsize=8, ha='center', va='center')\n",
    "axes[2].set_xlim(0, 256)\n",
    "axes[2].set_ylim(256, 0)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b6a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.imshow(patches[0], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2155cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "labels = to_categorical(labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31211e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the patches for logistic regression input\n",
    "X = patches.reshape(patches.shape[0], -1)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Build the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Step 3: Train the model\n",
    "model.fit(X_train, y_train.argmax(axis=1))  # Use argmax to convert one-hot labels to class indices\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test.argmax(axis=1), y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf30697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Small', 'Large'])\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title('Logistic Regession - Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize patches\n",
    "# patches[:,:,:,0] = (patches[:,:,:,0] - patches[:,:,:,0].min()) / (patches[:,:,:,0].max() - patches[:,:,:,0].min())\n",
    "# patches[:,:,:,1] = (patches[:,:,:,1] - patches[:,:,:,1].min()) / (patches[:,:,:,1].max() - patches[:,:,:,1].min())\n",
    "# patches[:,:,:,2] = (patches[:,:,:,2] - patches[:,:,:,2].min()) / (patches[:,:,:,2].max() - patches[:,:,:,2].min())\n",
    "\n",
    "patches = (patches - patches.min()) / (patches.max() - patches.min())\n",
    "\n",
    "# Reshape patches for CNN input\n",
    "patches = patches.reshape(-1, 15, 15, 3)\n",
    "\n",
    "\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(patches, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abaf548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157be664",
   "metadata": {},
   "outputs": [],
   "source": [
    "## New Model Definition 14/07/2025\n",
    "from tensorflow.keras.layers import Activation  # Import Activation layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu', input_shape=(15, 15, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=96, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))  # Adjusted strides to prevent shrinking too much\n",
    "\n",
    "model.add(Conv2D(filters=96, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))  # Adjusted strides to prevent shrinking too much\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2576e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import tensorflow as tf\n",
    "\n",
    "# Ensure CPU only\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return 1 - ((2. * intersection + smooth) /\n",
    "                (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth))\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "    return bce + dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f615c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "# # Build the CNN model\n",
    "# model = Sequential([\n",
    "#     Conv2D(32, (3, 3), activation='relu', input_shape=(15, 15, 3)),  # Updated input_shape to (15, 15, 3)\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Flatten(),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 3: Train the model\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=32), epochs=20, validation_data=(X_test, y_test), steps_per_epoch=len(X_train) // 32) \n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caa9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def add_layer(ax, x, y, width, height, label, color='skyblue'):\n",
    "    rect = patches.Rectangle((x, y), width, height, linewidth=1.5, edgecolor='k', facecolor=color)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x + width/2, y + height + 0.1, label, ha='center', fontsize=10)\n",
    "\n",
    "def draw_model():\n",
    "    fig, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.set_xlim(0, 12)\n",
    "    ax.set_ylim(0, 3)\n",
    "    ax.axis('off')\n",
    "\n",
    "    layer_params = [\n",
    "        (0.5, 1.0, 1.0, 1.0, 'Input\\n15×15×3', 'lightgrey'),\n",
    "        (2.0, 1.0, 1.2, 1.2, 'Conv2D\\n32@3×3', 'skyblue'),\n",
    "        (3.7, 1.0, 1.2, 1.2, 'MaxPool\\n2×2', 'lightgreen'),\n",
    "        (5.4, 1.0, 0.8, 1.2, 'Flatten', 'orange'),\n",
    "        (6.7, 1.0, 1.4, 1.2, 'Dense\\n64 units', 'salmon'),\n",
    "        (8.6, 1.0, 1.2, 1.2, 'Output\\n2-class\\nSoftmax', 'plum')\n",
    "    ]\n",
    "\n",
    "    for x, y, w, h, label, color in layer_params:\n",
    "        add_layer(ax, x, y, w, h, label, color)\n",
    "\n",
    "    # Optional arrows\n",
    "    for i in range(len(layer_params)-1):\n",
    "        x_start = layer_params[i][0] + layer_params[i][2]\n",
    "        x_end = layer_params[i+1][0]\n",
    "        y = 1.6\n",
    "        ax.annotate('', xy=(x_end, y), xytext=(x_start, y),\n",
    "                    arrowprops=dict(arrowstyle='->', lw=1.5))\n",
    "\n",
    "    plt.title(\"CNN Architecture (Keras Sequential Model)\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "draw_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c247875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_layer(ax, x, y, width, height, depth, color='skyblue', label=None, max_depth_drawn=10):\n",
    "    \"\"\"\n",
    "    Draw a stack of rectangles to represent a layer.\n",
    "    Only up to `max_depth_drawn` layers are drawn for clarity.\n",
    "    \"\"\"\n",
    "    depth_step = 0.2  # depth offset for layering\n",
    "    num_to_draw = min(depth, max_depth_drawn)\n",
    "    for i in range(num_to_draw):\n",
    "        offset = i * depth_step\n",
    "        rect = patches.Rectangle((x - offset, y - offset), width, height, linewidth=1, edgecolor='black', facecolor=color, alpha=0.6)\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    if label:\n",
    "        ax.text(x + width/2, y + height + 1.5, label, ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_xlim(0, 50)\n",
    "ax.set_ylim(0, 20)\n",
    "ax.axis('off')\n",
    "\n",
    "# Define and draw each layer\n",
    "layers = [\n",
    "    {\"x\": 2, \"y\": 5, \"w\": 4, \"h\": 4, \"d\": 3,  \"label\": \"Input\\n15x15x3\"},\n",
    "    {\"x\": 8, \"y\": 5, \"w\": 4, \"h\": 4, \"d\": 32, \"label\": \"Conv2D\\n13x13x32\"},\n",
    "    {\"x\": 14, \"y\": 5, \"w\": 3, \"h\": 3, \"d\": 32, \"label\": \"MaxPool\\n6x6x32\"},\n",
    "    {\"x\": 20, \"y\": 5, \"w\": 2.5, \"h\": 2.5, \"d\": 1, \"label\": \"Flatten\\n1152\"},\n",
    "    {\"x\": 26, \"y\": 5, \"w\": 2, \"h\": 2, \"d\": 1, \"label\": \"Dense\\n64\"},\n",
    "    {\"x\": 32, \"y\": 5, \"w\": 1.5, \"h\": 1.5, \"d\": 1, \"label\": \"Output\\n2 (Softmax)\"}\n",
    "]\n",
    "\n",
    "for layer in layers:\n",
    "    draw_layer(ax, layer[\"x\"], layer[\"y\"], layer[\"w\"], layer[\"h\"], layer[\"d\"], label=layer[\"label\"])\n",
    "\n",
    "plt.title(\"LeNet-style CNN Architecture\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8487bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_layer(ax, x, y, w, h, depth, color, label, offset=0.2):\n",
    "    for i in range(depth):\n",
    "        rect = patches.Rectangle((x + i * offset, y - i * offset), w, h, \n",
    "                                 linewidth=1, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    ax.text(x + depth * offset + 0.5, y + h / 2, label, fontsize=10, va='center')\n",
    "\n",
    "def draw_kernel_connection(ax, x1, y1, w1, h1, x2, y2, w2, h2, kernel_size):\n",
    "    # Kernel outline on input layer\n",
    "    kx, ky = x1 + w1/2 - kernel_size/2, y1 + h1/2 - kernel_size/2\n",
    "    ax.add_patch(patches.Rectangle((kx, ky), kernel_size, kernel_size, \n",
    "                                   linewidth=2, edgecolor='black', facecolor='none'))\n",
    "    # Arrow to next layer\n",
    "    ax.annotate('', xy=(x2, y2 + h2/2), xytext=(kx + kernel_size, ky + kernel_size/2),\n",
    "                arrowprops=dict(arrowstyle='->', lw=1.5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_xlim(0, 20)\n",
    "ax.set_ylim(0, 10)\n",
    "ax.axis('off')\n",
    "\n",
    "# Input layer: 15x15x3\n",
    "draw_layer(ax, 1, 4, 3, 3, 3, 'blue', 'Input\\n15×15×3')\n",
    "\n",
    "# Conv layer: 32@13x13\n",
    "draw_layer(ax, 5, 4, 2.6, 2.6, 5, 'green', 'Conv2D\\n32×13×13')\n",
    "draw_kernel_connection(ax, 1, 4, 3, 3, 5, 4, 2.6, 2.6, kernel_size=0.6)\n",
    "\n",
    "# MaxPooling layer: 32@6x6\n",
    "draw_layer(ax, 9, 4, 1.2, 1.2, 5, 'purple', 'MaxPool\\n32×6×6')\n",
    "\n",
    "# Flatten: vector of 1152\n",
    "draw_layer(ax, 12, 4.5, 0.6, 1, 1, 'orange', 'Flatten\\n1152')\n",
    "\n",
    "# Dense 64\n",
    "draw_layer(ax, 14, 4.5, 0.6, 1, 3, 'red', 'Dense\\n64')\n",
    "\n",
    "# Output layer: 2 classes\n",
    "draw_layer(ax, 16, 4.5, 0.6, 1, 2, 'black', 'Output\\n2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8076c28c",
   "metadata": {},
   "source": [
    "## AFM only Dataset Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Prepare the dataset\n",
    "patches = []\n",
    "labels = []\n",
    "\n",
    "for file, data in all_data_dict.items():\n",
    "    if True:\n",
    "        print('file: ', file)\n",
    "        spots = data['spots']\n",
    "        print('spots: ', len(spots))\n",
    "        spot_sizes = data['spot_sizes']\n",
    "        afm_img = data['afm_img']\n",
    "        # rbf_x = data['rbf_x']\n",
    "        # rbf_y = data['rbf_y']\n",
    "        # cl_img = data['cl_img']\n",
    "        # cl_raw = data['cl_raw']\n",
    "        # cl_centre = data['m_centre'].data\n",
    "        # cl_intensity = data['m_intensity'].data\n",
    "        # cl_fwhm = data['m_fwhm'].data\n",
    "\n",
    "        # source_points, target_points = load_feature_points(data['alignment_file'])\n",
    "\n",
    "        # h, w = afm_img.shape[:2]\n",
    "\n",
    "        # # Create a grid of pixel coordinates\n",
    "        # grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "        # grid_points = np.column_stack([grid_x.ravel(), grid_y.ravel()])\n",
    "\n",
    "        # # Interpolate transformation using RBF (thin-plate spline kernel)\n",
    "        # rbf_x = RBFInterpolator(source_points, target_points[:, 0], kernel='thin_plate_spline')\n",
    "        # rbf_y = RBFInterpolator(source_points, target_points[:, 1], kernel='thin_plate_spline')\n",
    "\n",
    "        # # Compute the transformed coordinates\n",
    "        # warped_x = rbf_x(grid_points).reshape(h, w).astype(np.float32)\n",
    "        # warped_y = rbf_y(grid_points).reshape(h, w).astype(np.float32)\n",
    "        \n",
    "        # warped_image_afm = cv2.remap(afm_img, warped_x, warped_y, interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Classify spots into largest 50% and smallest 50%\n",
    "        median_size = np.percentile(spot_sizes, 41) #np.median(spot_sizes)\n",
    "\n",
    "        # cl_spot_coords = []\n",
    "\n",
    "        for spot, size in zip(spots, spot_sizes):\n",
    "            # Get the AFM spot coordinates\n",
    "            afm_coords = np.array(spot.centroid)\n",
    "            \n",
    "            # # Map to CL image coordinates\n",
    "            # blank_array = np.zeros_like(afm_img)\n",
    "            # blank_array[int(afm_coords[0]), int(afm_coords[1])] = 255\n",
    "            # blank_array[int(afm_coords[0]), int(afm_coords[1]+1)] = 127\n",
    "            # blank_array[int(afm_coords[0]), int(afm_coords[1]-1)] = 127\n",
    "            # blank_array[int(afm_coords[0]+1), int(afm_coords[1])] = 127\n",
    "            # blank_array[int(afm_coords[0]-1), int(afm_coords[1])] = 127\n",
    "            # blank_array[int(afm_coords[0]+1), int(afm_coords[1]+1)] = 127\n",
    "            # blank_array[int(afm_coords[0]+1), int(afm_coords[1]-1)] = 127\n",
    "            # blank_array[int(afm_coords[0]-1), int(afm_coords[1]+1)] = 127\n",
    "            # blank_array[int(afm_coords[0]-1), int(afm_coords[1]-1)] = 127\n",
    "            # # Use RBF to get CL coordinates\n",
    "            # warped_image = cv2.remap(blank_array, warped_x, warped_y, interpolation=cv2.INTER_CUBIC)\n",
    "            # # Find the maximum value in warped_image\n",
    "            # max_value = np.max(warped_image)\n",
    "            # # Find the coordinates of the maximum value\n",
    "            # max_coords = np.argwhere(warped_image == max_value)\n",
    "\n",
    "            # cl_x, cl_y = max_coords[0]  # Get the first coordinate pair\n",
    "            print(f'AFM coordinates are {afm_coords[0]} and {afm_coords[1]}')\n",
    "\n",
    "            # AFM only: set cl_x and cl_y to afm_coords\n",
    "            cl_x, cl_y = int(afm_coords[1]), int(afm_coords[0])  # Note: (x, y) -> (col, row)\n",
    "\n",
    "            # print(f'CL coordinates are {cl_x} and {cl_y}')\n",
    "\n",
    "            # cl_spot_coords.append((cl_x, cl_y))\n",
    "\n",
    "            # Extract a 15x15 patch around the spot\n",
    "            half_size = 7  # Half of 15px\n",
    "\n",
    "            print('cl_img size = ', cl_img.shape)\n",
    "\n",
    "            # if (cl_y - half_size >= 0 and cl_y + half_size < cl_img.shape[0] and\n",
    "            #     cl_x - half_size >= 0 and cl_x + half_size < cl_img.shape[1]):\n",
    "            #     patch_centre = cl_centre[cl_y - half_size:cl_y + half_size + 1, cl_x - half_size:cl_x + half_size + 1]\n",
    "            #     patch_intensity = cl_intensity[cl_y - half_size:cl_y + half_size + 1, cl_x - half_size:cl_x + half_size + 1]\n",
    "            #     patch_fwhm = cl_fwhm[cl_y - half_size:cl_y + half_size + 1, cl_x - half_size:cl_x + half_size + 1]\n",
    "            #     patch_raw = cl_raw[cl_y - half_size:cl_y + half_size + 1, cl_x - half_size:cl_x + half_size + 1, :]\n",
    "            #     patch = np.stack((patch_centre,\n",
    "            #                       patch_intensity,\n",
    "            #                       patch_fwhm), axis=-1)\n",
    "            #     # patch = patch_raw\n",
    "\n",
    "            if (cl_y - half_size >= 0 and cl_y + half_size < cl_img.shape[0] and\n",
    "                cl_x - half_size >= 0 and cl_x + half_size < cl_img.shape[1]):\n",
    "                patch = afm_img[cl_y - half_size:cl_y + half_size + 1, cl_x - half_size:cl_x + half_size + 1]\n",
    "\n",
    "\n",
    "                patches.append(patch)\n",
    "                labels.append(1 if size > median_size else 0)\n",
    "        \n",
    "print('total number of patches = ', len(patches))\n",
    "print('total number of labels = ', len(labels))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "patches = np.array(patches)\n",
    "labels = np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547bf300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "csv_directory = r\"C:\\Users\\cobia\\OneDrive - University of Cambridge\\Python\\afm_data - Copy\\cobi\\labels\"\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [os.path.join(csv_directory, file) for file in os.listdir(csv_directory) if file.endswith('.csv')]\n",
    "\n",
    "# Load all CSV files into a single pandas DataFrame, adding the filename as a column\n",
    "dataframes = [pd.read_csv(file).assign(filename=os.path.basename(file)) for file in csv_files]\n",
    "combined_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd09a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "afm_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8385321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a box and whisker plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "combined_dataframe.boxplot(column='size', by='category', grid=False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Size')\n",
    "plt.title('Box and Whisker Plot: Size by Category')\n",
    "plt.suptitle('')  # Remove the default title added by pandas\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59645cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of images to display\n",
    "num_images = 50\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(int(num_images / 5) + 1, 5, figsize=(11, 30))\n",
    "\n",
    "# Loop through the first 10 patches and display them\n",
    "for i in range(num_images):\n",
    "    row, col = divmod(i, 5)  # Calculate row and column indices\n",
    "    axes[row, col].imshow(patches[i+1], cmap='gray')\n",
    "    axes[row, col].axis('off')\n",
    "    label = \"Large\" if labels[i+1][1] == 1 else \"Small\"\n",
    "    axes[row, col].set_title(f\"Patch {i+1}\\n{label}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2fb53e",
   "metadata": {},
   "source": [
    "### Tain CNN on AFM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "labels = to_categorical(labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b39969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619cbc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = patches.reshape(-1, 15, 15, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(patches, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a84f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ec24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## New Model Definition 14/07/2025\n",
    "from tensorflow.keras.layers import Activation  # Import Activation layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu', input_shape=(15, 15, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=96, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))  # Adjusted strides to prevent shrinking too much\n",
    "\n",
    "model.add(Conv2D(filters=96, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))  # Adjusted strides to prevent shrinking too much\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches = (patches - patches.min()) / (patches.max() - patches.min())\n",
    "\n",
    "# # Reshape patches for CNN input and add a channel dimension\n",
    "# patches = patches.reshape(-1, 15, 15, 1)  # Add channel dimension (e.g., grayscale images)\n",
    "\n",
    "\n",
    "\n",
    "# # Split into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(patches, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Build the CNN model\n",
    "# model = Sequential([\n",
    "#     Conv2D(32, (3, 3), activation='relu', input_shape=(15, 15, 1)),  # Updated input_shape to (15, 15, 1)\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Flatten(),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(2, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "#model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=32), epochs=10, validation_data=(X_test, y_test), steps_per_epoch=len(X_train) // 32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import requires\n",
    "print(requires(\"pySPM\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06612013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "y_true_classes = np.argmax(y_test, axis=1)  # Convert one-hot encoded labels to class labels\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Display the confusion matrix with increased font size\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Small', 'Large'])\n",
    "disp.plot(cmap='Blues')# , xticks_rotation=45, text_kw={'fontsize': 22})  # Increase font size for text\n",
    "plt.title('3D CNN Confusion Matrix')#, fontsize=20)  # Increase title font size\n",
    "plt.xlabel('Predicted Labels')#, fontsize=18)  # Increase x-axis label font size\n",
    "plt.ylabel('True Labels')#, fontsize=18)  # Increase y-axis label font size\n",
    "\n",
    "# Increase font size of axis tick mark labels\n",
    "#plt.xticks(fontsize=14)\n",
    "#plt.yticks(fontsize=14)\n",
    "\n",
    "# Adjust legend font size\n",
    "#plt.legend(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig('confusion_matrix_afm.png', dpi=600, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e539d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "im = ax.imshow(patches[0, :, :, 0], cmap='RdBu')\n",
    "cbar = fig.colorbar(im, ax=ax)\n",
    "cbar.set_label('Energy (eV) vs mean', fontsize=12)\n",
    "ax.set_title('Example Patch Visualization', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72abacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8243e6e7",
   "metadata": {},
   "source": [
    "### Make a slider to adjust parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b7bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c4b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = afm_files[0]  # Replace with your image file path\n",
    "\n",
    "# Define the range of block sizes and offsets\n",
    "block_sizes = [15, 31, 51, 71, 91]\n",
    "offsets = [2000, 3000, 4000, 5000]\n",
    "\n",
    "# Create a figure to display the results\n",
    "fig, axes = plt.subplots(len(block_sizes), len(offsets), figsize=(11, 11))\n",
    "\n",
    "\n",
    "image = io.imread(file, as_gray=True)\n",
    "# Fit a plane to the image\n",
    "x, y = np.meshgrid(np.arange(image.shape[1]), np.arange(image.shape[0]))\n",
    "A = np.c_[x.ravel(), y.ravel(), np.ones_like(x.ravel())]\n",
    "coeff, _, _, _ = np.linalg.lstsq(A, image.ravel(), rcond=None)\n",
    "plane = (coeff[0] * x + coeff[1] * y + coeff[2]).reshape(image.shape)\n",
    "\n",
    "# Set any pixel with a value higher than the plane to the level of the plane\n",
    "filtered_image = np.minimum(image, plane)\n",
    "\n",
    "\n",
    "# Loop through each combination of block size and offset\n",
    "for i, block_size in enumerate(block_sizes):\n",
    "    for j, offset in enumerate(offsets):\n",
    "        # Perform local thresholding\n",
    "        threshold_image = filters.threshold_local(filtered_image, block_size=block_size, offset=offset)\n",
    "        dark_spots_image = filtered_image < threshold_image\n",
    "\n",
    "        # Label the dark spots\n",
    "        labeled_spots, num_spots = ndi.label(dark_spots_image)\n",
    "\n",
    "        # Find the coordinates and sizes of the spots\n",
    "        spots = measure.regionprops(labeled_spots)\n",
    "        spot_sizes = [spot.area for spot in spots if 2 <= spot.area <= 100]\n",
    "\n",
    "        axes[i,j].imshow(image, cmap='afmhot')\n",
    "        for spot in spots:\n",
    "            if 2 <= spot.area <= 100:\n",
    "                cy, cx = spot.centroid\n",
    "                contour = measure.find_contours(labeled_spots == spot.label, 0.5)\n",
    "                for n, contour in enumerate(contour):\n",
    "                    axes[i,j].plot(contour[:, 1], contour[:, 0], linewidth=1, color='blue')\n",
    "        \n",
    "        # Display the result\n",
    "        \n",
    "        axes[i, j].set_title(f'block_size={block_size}, offset={offset}')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7781602",
   "metadata": {},
   "source": [
    "## Tkinter Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b9fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "\n",
    "# Define image\n",
    "image1 = all_data_dict['fat_end_outside_L_03.0_00000.png']['afm_img']\n",
    "spots_image1 = all_data_dict['fat_end_outside_L_03.0_00000.png']['spots']\n",
    "\n",
    "# Initialize a DataFrame to store categorized spots\n",
    "spot_data = pd.DataFrame(columns=['x', 'y', 'size', 'category'])\n",
    "\n",
    "# CSV file path to save categorized spots\n",
    "csv_file_path = 'categorized_spots.csv'\n",
    "\n",
    "# Stack to keep track of categorized spots for undo functionality\n",
    "undo_stack = []\n",
    "\n",
    "# Counter to track the current spot index\n",
    "current_spot_index = 0\n",
    "total_spots = len([spot for spot in spots_image1 if 5 <= spot.area <= 100])\n",
    "\n",
    "# Function to update the counter label\n",
    "def update_counter_label():\n",
    "    counter_label.config(text=f\"Spot {current_spot_index + 1} of {total_spots}\")\n",
    "\n",
    "# Function to handle spot categorization\n",
    "def categorize_spot(category, spot, canvas, spots_iter, root):\n",
    "    global spot_data, undo_stack, current_spot_index, first_spot\n",
    "    if category == \"not_a_spot\":\n",
    "        print(f\"Spot at ({spot.centroid[1]:.1f}, {spot.centroid[0]:.1f}) labeled as 'Not a Spot'.\")\n",
    "        # Push the categorized spot onto the undo stack\n",
    "        undo_stack.append((spot, category))\n",
    "    elif category == \"combination\":\n",
    "        print(f\"Spot at ({spot.centroid[1]:.1f}, {spot.centroid[0]:.1f}) labeled as 'Combination of Multiple Spots'.\")\n",
    "\n",
    "        # Temporarily commenting out the re-thresholding and user verification part\n",
    "\n",
    "        # # Re-threshold the region around the spot\n",
    "        # minr, minc, maxr, maxc = spot.bbox\n",
    "        # sub_image = image1[minr:maxr, minc:maxc]\n",
    "        # sub_threshold = filters.threshold_local(sub_image, block_size=11, offset=2048)\n",
    "        # sub_dark_spots = sub_image < sub_threshold\n",
    "        # sub_labeled_spots, _ = ndi.label(sub_dark_spots)\n",
    "        # sub_spots = measure.regionprops(sub_labeled_spots)\n",
    "        \n",
    "        # # Display the re-thresholded region for user verification\n",
    "        # sub_image_pil = Image.fromarray(sub_image)\n",
    "        # sub_image_tk = ImageTk.PhotoImage(sub_image_pil)\n",
    "        # sub_window = tk.Toplevel(root)\n",
    "        # sub_window.title(\"Re-thresholded Spot Region\")\n",
    "        # sub_canvas = tk.Canvas(sub_window, width=sub_image.shape[1], height=sub_image.shape[0], bg=\"white\")\n",
    "        # sub_canvas.pack()\n",
    "        # sub_canvas.create_image(0, 0, anchor=tk.NW, image=sub_image_tk)\n",
    "        # sub_window.mainloop()\n",
    "        # print(\"Please verify if the separation of spots was successful.\")\n",
    "\n",
    "        spot_data = pd.concat([spot_data, pd.DataFrame({\n",
    "            'x': [spot.centroid[1]],\n",
    "            'y': [spot.centroid[0]],\n",
    "            'size': [spot.area],\n",
    "            'category': [category]\n",
    "        })], ignore_index=True)\n",
    "        # Push the categorized spot onto the undo stack\n",
    "        undo_stack.append((spot, category))\n",
    "\n",
    "    else:\n",
    "        # Add the spot to the DataFrame\n",
    "        spot_data = pd.concat([spot_data, pd.DataFrame({\n",
    "            'x': [spot.centroid[1]],\n",
    "            'y': [spot.centroid[0]],\n",
    "            'size': [spot.area],\n",
    "            'category': [category]\n",
    "        })], ignore_index=True)\n",
    "        # Push the categorized spot onto the undo stack\n",
    "        undo_stack.append((spot, category))\n",
    "        print(f\"Spot at ({spot.centroid[1]:.1f}, {spot.centroid[0]:.1f}) labeled as '{category}'.\")\n",
    "\n",
    "    # Save to CSV file\n",
    "    spot_data.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Move to the next spot\n",
    "    try:\n",
    "        next_spot = next(spots_iter)\n",
    "        first_spot = next_spot\n",
    "        current_spot_index += 1\n",
    "        update_counter_label()\n",
    "        highlight_spot(next_spot, canvas)\n",
    "    except StopIteration:\n",
    "        print(\"All spots have been categorized.\")\n",
    "        root.destroy()\n",
    "\n",
    "# Function to undo the last categorization\n",
    "def undo_last_action(canvas, spots_iter):\n",
    "    global spot_data, undo_stack, current_spot_index\n",
    "    if undo_stack:\n",
    "        last_spot, last_category = undo_stack.pop()\n",
    "        # Remove the last categorized spot from the DataFrame\n",
    "        spot_data = spot_data[~((spot_data['x'] == last_spot.centroid[1]) & \n",
    "                                (spot_data['y'] == last_spot.centroid[0]) & \n",
    "                                (spot_data['category'] == last_category))]\n",
    "        print(f\"Undo: Removed spot at ({last_spot.centroid[1]:.1f}, {last_spot.centroid[0]:.1f}) labeled as '{last_category}'.\")\n",
    "        # Highlight the undone spot again\n",
    "        highlight_spot(last_spot, canvas)\n",
    "        # Re-add the undone spot to the iterator\n",
    "        print(\"New List: \" + str([last_spot] + list(spots_iter)))\n",
    "        spots_iter = iter([last_spot] + list(spots_iter))\n",
    "        current_spot_index -= 1\n",
    "        update_counter_label()\n",
    "    else:\n",
    "        print(\"Nothing to undo.\")\n",
    "\n",
    "# Function to highlight a spot on the canvas\n",
    "def highlight_spot(spot, canvas):\n",
    "    canvas.delete(\"highlight\")\n",
    "    x, y = spot.centroid[1], spot.centroid[0]\n",
    "    canvas.create_oval(x-8, y-8, x+8, y+8, outline=\"yellow\", width=2, tags=\"highlight\")\n",
    "    canvas.update()\n",
    "\n",
    "\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Spot Categorization\")\n",
    "\n",
    "# Create a canvas to display the image\n",
    "canvas = tk.Canvas(root, width=image1.shape[1], height=image1.shape[0], bg=\"white\")\n",
    "canvas.pack()\n",
    "\n",
    "# Convert the image to a format suitable for tkinter\n",
    "image1_pil = Image.fromarray(image1)\n",
    "image1_tk = ImageTk.PhotoImage(image1_pil)\n",
    "canvas.create_image(0, 0, anchor=tk.NW, image=image1_tk)\n",
    "\n",
    "# Create a frame for buttons\n",
    "button_frame = tk.Frame(root)\n",
    "button_frame.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "# Create an iterator for the spots\n",
    "spots_iter = iter([spot for spot in spots_image1 if 5 <= spot.area <= 100])\n",
    "\n",
    "# Highlight the first spot\n",
    "try:\n",
    "    global first_spot\n",
    "    first_spot = next(spots_iter)\n",
    "    highlight_spot(first_spot, canvas)\n",
    "except StopIteration:\n",
    "    print(\"No spots to categorize.\")\n",
    "    root.destroy()\n",
    "\n",
    "# Create a counter label\n",
    "counter_label = tk.Label(root, text=f\"Spot 1 of {total_spots}\", font=(\"Arial\", 12))\n",
    "counter_label.pack()\n",
    "\n",
    "# Create buttons for categorization\n",
    "categories = [('Large', 'large'),\n",
    "              ('Small', 'small'),\n",
    "              ('Not a Spot', 'not_a_spot'),\n",
    "              ('Combination', 'combination')]\n",
    "for text, category in categories:\n",
    "    button = ttk.Button(button_frame, text=text, command=lambda c=category: categorize_spot(c, first_spot, canvas, spots_iter, root))\n",
    "    button.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "    button.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "# Add an Undo button\n",
    "undo_button = ttk.Button(button_frame, text=\"Undo\", command=lambda: undo_last_action(canvas, spots_iter))\n",
    "undo_button.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "\n",
    "# Define image\n",
    "image1 = all_data_dict['fat_end_outside_L_03.0_00000.png']['afm_img']\n",
    "spots_image1 = all_data_dict['fat_end_outside_L_03.0_00000.png']['spots']\n",
    "\n",
    "# Initialise a DataFrame to store categorised spots\n",
    "spot_data = pd.DataFrame(columns=['x', 'y', 'size', 'category'])\n",
    "\n",
    "# CSV file path to save categorised spots\n",
    "csv_file_path = 'categorised_spots.csv'\n",
    "\n",
    "# Stack to keep track of categorised spots for undo functionality\n",
    "undo_stack = []\n",
    "\n",
    "# Counter to track the current spot index\n",
    "current_spot_index = 0\n",
    "total_spots = len([spot for spot in spots_image1 if 5 <= spot.area <= 100])\n",
    "\n",
    "# Function to update the counter label\n",
    "def update_counter_label(manual=False):\n",
    "    if manual:\n",
    "        counter_label.config(text=f\"Manual Categorisation. Click any undetected spots.\")\n",
    "    else:\n",
    "        counter_label.config(text=f\"Spot {current_spot_index + 1} of {total_spots}\")\n",
    "\n",
    "# Function to handle user clicks for undetected spots\n",
    "def on_canvas_click(event):\n",
    "    global spot_data, undo_stack\n",
    "    x, y = event.x, event.y\n",
    "    print(f\"User clicked at ({x}, {y}).\")\n",
    "\n",
    "    # Create a pop-up window for categorisation\n",
    "    popup = tk.Toplevel(root)\n",
    "    popup.title(\"Categorise Spot\")\n",
    "    popup.geometry(\"300x150\")\n",
    "\n",
    "    label = tk.Label(popup, text=f\"Categorise the spot at ({x}, {y}):\", font=(\"Arial\", 12))\n",
    "    label.pack(pady=10)\n",
    "\n",
    "    def categorise_new_spot(category):\n",
    "        global spot_data, undo_stack\n",
    "        print(f\"Spot at ({x}, {y}) labeled as '{category}'.\")\n",
    "        # Add the new spot to the DataFrame\n",
    "        spot_data = pd.concat([spot_data, pd.DataFrame({\n",
    "            'x': [x],\n",
    "            'y': [y],\n",
    "            'size': [None],  # Size is unknown for manually added spots\n",
    "            'category': [category]\n",
    "        })], ignore_index=True)\n",
    "        # Push the categorised spot onto the undo stack\n",
    "        undo_stack.append(({'x': x, 'y': y}, category))\n",
    "        # Save to CSV file\n",
    "        spot_data.to_csv(csv_file_path, index=False)\n",
    "        popup.destroy()\n",
    "\n",
    "    # Buttons for categorisation\n",
    "    large_button = ttk.Button(popup, text=\"Large\", command=lambda: categorise_new_spot(\"large\"))\n",
    "    large_button.pack(side=tk.LEFT, padx=20, pady=20)\n",
    "\n",
    "    small_button = ttk.Button(popup, text=\"Small\", command=lambda: categorise_new_spot(\"small\"))\n",
    "    small_button.pack(side=tk.RIGHT, padx=20, pady=20)\n",
    "\n",
    "# Function to highlight all spots\n",
    "def highlight_all_spots():\n",
    "    canvas.delete(\"highlight\")\n",
    "    for spot in spots_image1:\n",
    "        x, y = spot.centroid[1], spot.centroid[0]\n",
    "        canvas.create_oval(x-8, y-8, x+8, y+8, outline=\"yellow\", width=2, tags=\"highlight\")\n",
    "    canvas.update()\n",
    "\n",
    "# Function to finish the manual categorisation phase\n",
    "def finish_manual_categorisation():\n",
    "    print(\"Manual categorisation finished.\")\n",
    "    root.destroy()\n",
    "\n",
    "# After all spots are categorised\n",
    "def start_manual_categorisation():\n",
    "    print(\"All spots have been categorised. Highlighting all spots.\")\n",
    "    update_counter_label(manual=True)\n",
    "    highlight_all_spots()\n",
    "    canvas.bind(\"<Button-1>\", on_canvas_click)\n",
    "\n",
    "    # Add a Finish button\n",
    "    finish_button = ttk.Button(button_frame, text=\"Finish\", command=finish_manual_categorisation)\n",
    "    finish_button.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "# Modify the categorise_spot function to call start_manual_categorisation\n",
    "def categorise_spot(category, spot, canvas, root):\n",
    "    global spot_data, undo_stack, current_spot_index, first_spot, spots_iter\n",
    "    if category == \"skip\":\n",
    "        print('Skipping categorisation function for undo')\n",
    "    elif category == \"not_a_spot\":\n",
    "        print(f\"Spot at ({spot.centroid[1]:.1f}, {spot.centroid[0]:.1f}) labeled as 'Not a Spot'.\")\n",
    "        undo_stack.append((spot, category))\n",
    "    elif category == \"combination\":\n",
    "        print(f\"Spot at ({spot.centroid[1]:.1f}, {spot.centroid[0]:.1f}) labeled as 'Combination of Multiple Spots'.\")\n",
    "        spot_data = pd.concat([spot_data, pd.DataFrame({\n",
    "            'x': [spot.centroid[1]],\n",
    "            'y': [spot.centroid[0]],\n",
    "            'size': [spot.area],\n",
    "            'category': [category]\n",
    "        })], ignore_index=True)\n",
    "        undo_stack.append((spot, category))\n",
    "    else:\n",
    "        spot_data = pd.concat([spot_data, pd.DataFrame({\n",
    "            'x': [spot.centroid[1]],\n",
    "            'y': [spot.centroid[0]],\n",
    "            'size': [spot.area],\n",
    "            'category': [category]\n",
    "        })], ignore_index=True)\n",
    "        undo_stack.append((spot, category))\n",
    "        print(f\"Spot at ({spot.centroid[1]:.1f}, {spot.centroid[0]:.1f}) labeled as '{category}'.\")\n",
    "\n",
    "    spot_data.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    try:\n",
    "        next_spot = next(spots_iter)\n",
    "        first_spot = next_spot\n",
    "        current_spot_index += 1\n",
    "        update_counter_label()\n",
    "        highlight_spot(next_spot, canvas)\n",
    "    except StopIteration:\n",
    "        start_manual_categorisation()\n",
    "\n",
    "# Function to undo the last categorisation\n",
    "def undo_last_action(canvas):\n",
    "    global spot_data, undo_stack, current_spot_index, spots_iter\n",
    "    if undo_stack:\n",
    "        last_spot, last_category = undo_stack.pop()\n",
    "        # Remove the last categorised spot from the DataFrame\n",
    "        spot_data = spot_data[~((spot_data['x'] == last_spot.centroid[1]) & \n",
    "                                (spot_data['y'] == last_spot.centroid[0]) & \n",
    "                                (spot_data['category'] == last_category))]\n",
    "        print(f\"Undo: Removed spot at ({last_spot.centroid[1]:.1f}, {last_spot.centroid[0]:.1f}) labeled as '{last_category}'.\")\n",
    "        # Highlight the undone spot again\n",
    "        highlight_spot(last_spot, canvas)\n",
    "        # Re-add the undone spot to the iterator\n",
    "        new_list = [last_spot] + list(spots_iter)\n",
    "        print(\"New List: \" + str(new_list))\n",
    "        spots_iter = iter(new_list)\n",
    "        current_spot_index -= 1\n",
    "        update_counter_label()\n",
    "        categorise_spot(\"skip\", last_spot, canvas, root)\n",
    "    else:\n",
    "        print(\"Nothing to undo.\")        \n",
    "\n",
    "\n",
    "# Function to highlight a spot on the canvas\n",
    "def highlight_spot(spot, canvas):\n",
    "    canvas.delete(\"highlight\")\n",
    "    x, y = spot.centroid[1], spot.centroid[0]\n",
    "    canvas.create_oval(x-8, y-8, x+8, y+8, outline=\"yellow\", width=2, tags=\"highlight\")\n",
    "    canvas.update()\n",
    "\n",
    "\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Spot Categorisation\")\n",
    "\n",
    "# Create a canvas to display the image\n",
    "canvas = tk.Canvas(root, width=image1.shape[1], height=image1.shape[0], bg=\"white\")\n",
    "canvas.pack()\n",
    "\n",
    "# Convert the image to a format suitable for tkinter\n",
    "image1_pil = Image.fromarray(image1)\n",
    "image1_tk = ImageTk.PhotoImage(image1_pil)\n",
    "canvas.create_image(0, 0, anchor=tk.NW, image=image1_tk)\n",
    "\n",
    "# Create a frame for buttons\n",
    "button_frame = tk.Frame(root)\n",
    "button_frame.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "# Create an iterator for the spots\n",
    "spots_iter = iter([spot for spot in spots_image1 if 5 <= spot.area <= 100])\n",
    "\n",
    "# Highlight the first spot\n",
    "try:\n",
    "    global first_spot\n",
    "    first_spot = next(spots_iter)\n",
    "    highlight_spot(first_spot, canvas)\n",
    "except StopIteration:\n",
    "    print(\"No spots to categorise.\")\n",
    "    root.destroy()\n",
    "\n",
    "# Create a counter label\n",
    "counter_label = tk.Label(root, text=f\"Spot 1 of {total_spots}\", font=(\"Arial\", 12))\n",
    "counter_label.pack()\n",
    "\n",
    "# Create buttons for categorisation\n",
    "categories = [('Large', 'large'),\n",
    "              ('Small', 'small'),\n",
    "              ('Not a Spot', 'not_a_spot'),\n",
    "              ('Combination', 'combination')]\n",
    "for text, category in categories:\n",
    "    button = ttk.Button(button_frame, text=text, command=lambda c=category: categorise_spot(c, first_spot, canvas, root))\n",
    "    button.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "    button.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "# Add an Undo button\n",
    "undo_button = ttk.Button(button_frame, text=\"Undo\", command=lambda: undo_last_action(canvas))\n",
    "undo_button.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc5ec16",
   "metadata": {},
   "source": [
    "## Gaussian Fit Figure Creation for FY Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20756c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_filename = all_data_dict['fat_end_outside_L_03.0_00000.png']['cl_file']\n",
    "cl_sem = hs.load(cl_filename, signal_type='CL_SEM')\n",
    "# Display the CL SEM image \n",
    "cl_sem.plot(image=True, cmap='viridis', title='CL SEM Image', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f956b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_sem.T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_sem_eV = cl_sem.to_eV(inplace=False, jacobian=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_sem_eV.plot(image=True, cmap='viridis', title='CL SEM Image in eV', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6734c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cl_sem_eV.create_model()\n",
    "bkg = hs.model.components1D.Offset()\n",
    "g1 = hs.model.components1D.GaussianHF()\n",
    "m.extend([g1, bkg])\n",
    "cl_sem_eV.axes_manager.indices = (17,17)\n",
    "g1.centre.value = 3.4        # Gaussian centre\n",
    "g1.fwhm.value = 0.1      # Gaussian width\n",
    "g1.height.value = 100      # Gaussian height\n",
    "bkg.offset.value = 0.1   # background offset\n",
    "g1.centre.bmax = g1.centre.value + 0.2\n",
    "g1.centre.bmin = g1.centre.value - 0.2\n",
    "g1.fwhm.bmin = 0.01\n",
    "m.fit()\n",
    "m.assign_current_values_to_all()\n",
    "m.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f69728",
   "metadata": {},
   "source": [
    "# Figure for Poster bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_filename = r\"C:\\Users\\cobia\\OneDrive - University of Cambridge\\CL\\COBI-20250501\\HYP-SI-FAT-END-OUTSIDE-07+6UM\\HYPCard_corrected.hspy\"\n",
    "\n",
    "im = hs.load(cl_filename, signal_type='CL_SEM').T\n",
    "\n",
    "im.plot()\n",
    "roi1 = hs.roi.SpanROI(left=350, right=380) #sets a digitalbandfilter\n",
    "im_roi1 = roi1.interactive(im, color=\"red\")\n",
    "im_roi1_mean = hs.interactive(im_roi1.mean,\n",
    "                        event=roi1.events.changed,\n",
    "                        recompute_out_event=None)\n",
    "\n",
    "cl_img = im_roi1_mean.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.imshow(cl_img, cmap='viridis')\n",
    "\n",
    "\n",
    "plt.savefig('cl_img.png', dpi=600, transparent=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33832c05",
   "metadata": {},
   "source": [
    "## Plot Numpy Fits from HPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.linalg import lstsq\n",
    "\n",
    "# ---- Change this to your folder ----\n",
    "data_dir = r\"C:\\Users\\cobia\\OneDrive - University of Cambridge\\CL\\numpy_fits\"\n",
    "\n",
    "# ---- Helper functions ----\n",
    "\n",
    "def remove_outliers(arr, z_thresh=5.0, filter_size=3):\n",
    "    \"\"\"\n",
    "    Remove extreme outliers based on a simple z-score-like measure.\n",
    "    Replace outliers with local median.\n",
    "    \"\"\"\n",
    "    # Median filter to estimate local background\n",
    "    med = median_filter(arr, size=filter_size)\n",
    "    diff = arr - med\n",
    "    mad = np.median(np.abs(diff))\n",
    "    outliers = np.abs(diff) > z_thresh * mad\n",
    "    arr_clean = arr.copy()\n",
    "    arr_clean[outliers] = med[outliers]  # interpolate with local median\n",
    "    return arr_clean\n",
    "\n",
    "def flatten_plane(arr):\n",
    "    \"\"\"\n",
    "    Fit a plane z = ax + by + c to the data and subtract it.\n",
    "    \"\"\"\n",
    "    nrows, ncols = arr.shape\n",
    "    X, Y = np.meshgrid(np.arange(ncols), np.arange(nrows))\n",
    "    A = np.c_[X.ravel(), Y.ravel(), np.ones(nrows*ncols)]\n",
    "    z = arr.ravel()\n",
    "    coeff, _, _, _ = lstsq(A, z)\n",
    "    plane = (coeff[0]*X + coeff[1]*Y + coeff[2])\n",
    "    return arr - plane\n",
    "\n",
    "# ---- Main loop ----\n",
    "\n",
    "plt.close('all')  # Close all previous plots\n",
    "\n",
    "intensity_files = glob.glob(os.path.join(data_dir, \"*_m_intensity.npy\"))\n",
    "\n",
    "for inten_file in intensity_files:\n",
    "    prefix = inten_file.replace(\"_m_intensity.npy\", \"\")\n",
    "    centre_file = prefix + \"_m_centre.npy\"\n",
    "\n",
    "    if not os.path.exists(centre_file):\n",
    "        print(f\"⚠️ Skipping {inten_file}, no matching centre file found.\")\n",
    "        continue\n",
    "\n",
    "    # Load arrays\n",
    "    inten = np.load(inten_file)\n",
    "    centre = np.load(centre_file)\n",
    "\n",
    "    # Remove outliers\n",
    "    inten_clean = remove_outliers(inten)\n",
    "    centre_clean = remove_outliers(centre)\n",
    "\n",
    "    # Flatten centre by subtracting mean plane\n",
    "    centre_flat = flatten_plane(centre_clean)\n",
    "\n",
    "    # Plot side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    im0 = axes[0].imshow(inten_clean, cmap=\"viridis\")\n",
    "    axes[0].set_title(os.path.basename(inten_file))\n",
    "    plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "    im1 = axes[1].imshow(centre_flat, cmap=\"gray\")\n",
    "    axes[1].set_title(os.path.basename(centre_file) + \" (flattened)\")\n",
    "    plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
